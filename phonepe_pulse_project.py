# -*- coding: utf-8 -*-
"""phonepe_pulse_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qk7BhCA39MD0QDt-dH7k0Ssds3Y8uqKP
"""

!pip install GitPython

import csv
import subprocess
import pandas as pd
import requests
import git
import pandas as pd

import os
import json
import pandas as pd

# Clone the GitHub repository
repo_url = "https://github.com/phonepe/pulse.git"
clone_dir = "pulse"

os.system(f"git clone {repo_url} {clone_dir}")

root_dir = os.path.join(clone_dir, "data", "aggregated", "transaction", "country", "india", "state")

data_list = []

for state_directory in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_directory)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for transaction_data in data['data']['transactionData']:
                                trans_data = {
                                    'States': state_directory,
                                    'Transaction_Year': year_dir,
                                    'Transaction_Type': transaction_data['name'],
                                    'Transaction_Count': transaction_data['paymentInstruments'][0]['count'],
                                    'Transaction_Amount': transaction_data['paymentInstruments'][0]['amount']
                                }
                                data_list.append(trans_data)

# Convert list of dictionaries to a DataFrame
data1 = pd.DataFrame(data_list)
data1.head()

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/aggregated/user/country/india/state'
data2_list = []

for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):
        for json_file in os.listdir(state_path):
            if json_file.endswith('.json'):
                with open(os.path.join(state_path, json_file), 'r') as f:
                    json_data = json.load(f)
                    if isinstance(json_data, list):
                        data2_list.extend(json_data)
                    else:
                        data2_list.append(json_data)
        if data2_list:
            data2 = pd.json_normalize(data2_list)
            data2['subfolder'] = state_dir
            data2['subsubfolder'] = 'state'
        else:
            data2 = pd.DataFrame()
data2.head()

data2 = pd.DataFrame(data_list)

data2

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list = []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for hoverDataList in data['data']['hoverDataList']:
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': hoverDataList['name'],
                                    'Transaction_Type': hoverDataList['metric'][0]['type'],
                                    'Transaction_Count': hoverDataList['metric'][0]['amount']
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data3 = pd.DataFrame(data_list)

data3

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/map/user/hover/country/india/state'

data_list = []

# Loop over all the state folders
for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for district, values in data['data']['hoverData'].items():
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarter': int(json_file.split('.')[0]),
                                    'District': district,
                                    'RegisteredUsers': values['registeredUsers'],
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data4 = pd.DataFrame(data_list)

data4

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

data_list = []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for districts in data['data']['districts']:
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': districts['entityName'],
                                    'Transaction_Type': districts['metric']['type'],
                                    'Transaction_Count': districts['metric']['count'],
                                    'Transaction_Amount': districts['metric']['amount']
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data5 = pd.DataFrame(data_list)

data5

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/top/user/country/india/state'

# Initialize empty list to hold dictionaries of data for each JSON file
data_list = []

# Loop over all the state folders
for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for district in data['data']['districts']:
                                row_dict = {
                                    'State': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': district['name'] if 'name' in district else district['pincode'],
                                    'RegisteredUsers': district['registeredUsers'],
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data6 = pd.DataFrame(data_list)
data6

# Drop any duplicates
d1 = data1.drop_duplicates()
#d2 = df2.drop_duplicates()
d3 = data3.drop_duplicates()
d4 = data4.drop_duplicates()
d5 = data5.drop_duplicates()
d6 = data6.drop_duplicates()

#checking Null values
null_counts = d1.isnull().sum()
print(null_counts)

#null_counts = d2.isnull().sum()
#print(null_counts)

null_counts = d3.isnull().sum()
print(null_counts)

null_counts = d4.isnull().sum()
print(null_counts)

null_counts = d5.isnull().sum()
print(null_counts)

null_counts = d6.isnull().sum()
print(null_counts)

#converting all dataframes in to csv
d1.to_csv('agg_trans.csv', index=False)
#df2.to_csv('agg_user.csv', index=False)
d3.to_csv('map_tran.csv', index=False)
d4.to_csv('map_user.csv', index=False)
d5.to_csv('top_tran.csv', index=False)
d6.to_csv('top_user.csv', index=False)

Agg_trans = pd.read_csv(r'/content/agg_trans.csv')
Agg_trans = pd.read_csv(r'/content/agg_trans.csv')
Agg_trans = pd.read_csv(r'/content/agg_trans.csv')
Agg_trans = pd.read_csv(r'/content/agg_trans.csv')
Agg_trans = pd.read_csv(r'/content/agg_trans.csv')
Agg_trans = pd.read_csv(r'/content/agg_trans.csv')

!pip install mysql-connector-python
!pip install streamlit plotly mysql-connector-python
!pip install streamlit
!pip install streamlit_option_menu

import mysql.connector
import pandas as pd
#import psycopg2
import streamlit as st
import PIL
from PIL import Image
from streamlit_option_menu import option_menu
import plotly.express as px
import pandas as pd

import requests

import mysql.connector

import sqlite3

sqlite_conn = sqlite3.connect('phonepe.db')
sqlite_cursor = sqlite_conn.cursor()

create_table_query = '''
CREATE TABLE aggTransa (
    id INTEGER PRIMARY KEY,
    transaction_date TEXT,
    amount REAL,
    description TEXT
)
'''

sqlite_cursor.execute(create_table_query)

# fetch all rows
rows = sqlite_cursor.fetchall()

# print the rows
for row in rows:
  print(row)

#sqlite_cursor.close()
#sqlite_conn.close()

!pip install streamlit
!pip install db-sqlite3
!pip install pyngrok --upgrade

import streamlit as st
import pandas as pd
import plotly.express as px
from PIL import Image

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import plotly.express as px
# from PIL import Image
# 
# SELECT = st.selectbox(
#     "Select an option",
#     ["About", "Home", "Basic insights", "Contact"],
#     index=2,
#     format_func=lambda x: x.upper(),
# )
# 
# if SELECT == "Basic insights":
#     st.title("BASIC INSIGHTS")
#     st.write("----")
#     st.subheader("Let's know some basic insights about the data")
#     options = [
#         "-- Select --",
#         "Top 10 states based on year and amount of transaction",
#         "List 10 states based on type and amount of transaction",
#         "Top 5 Transaction_Type based on Transaction_Amount",
#         "Top 10 Registered-users based on States and District",
#         "Top 10 Districts based on states and Count of transaction",
#         "List 10 Districts based on states and amount of transaction",
#         "List 10 Transaction_Count based on Districts and states",
#         "Top 10 RegisteredUsers based on states and District",
#     ]
#     select = st.selectbox("Select an option", options)
# 
#     if select == "Top 10 states based on year and amount of transaction":
#         sqlite_cursor.execute(
#             "SELECT DISTINCT States, Transaction_Year, SUM(Transaction_Amount) AS Total_Transaction_Amount FROM top_tran GROUP BY States, Transaction_Year ORDER BY Total_Transaction_Amount DESC LIMIT 10"
#         )
#         df = pd.DataFrame(
#             sqlite_cursor.fetchall(),
#             columns=["States", "Transaction_Year", "Transaction_Amount"],
#         )
#         st.write(df)
#         st.title("Top 10 states and amount of transaction")
#         st.bar_chart(data=df, x="Transaction_Amount", y="States")
# 
#     elif select == "List 10 states based on type and amount of transaction":
#         sqlite_cursor.execute(
#             "SELECT DISTINCT States, SUM(Transaction_Count) as Total FROM top_tran GROUP BY States ORDER BY Total ASC LIMIT 10"
#         )
#         df = pd.DataFrame(
#             sqlite_cursor.fetchall(), columns=["States", "Total_Transaction"]
#         )
#         st.write(df)
#         st.title("List 10 states based on type and amount of transaction")
#         st.bar_chart(data=df, x="Total_Transaction", y="States")
# 
#     elif select == "Top 5 Transaction_Type based on Transaction_Amount":
#         sqlite_cursor.execute(
#             "SELECT DISTINCT Transaction_Type, SUM(Transaction_Amount) AS Amount FROM agg_user GROUP BY Transaction_Type ORDER BY Amount DESC LIMIT 5"
#         )
#         df = pd.DataFrame(
#             sqlite_cursor.fetchall(), columns=["Transaction_Type", "Transaction_Amount"]
#         )
#         st.write(df)
#         st.title("Top 5 Transaction_Type based on Transaction_Amount")
#         st.bar_chart(data=df, x="Transaction_Type", y="Amount")
# 
#     elif select == "Top 10 Registered-users based on States and District":
#         sqlite_cursor.execute(
#             "SELECT DISTINCT State, District, SUM(RegisteredUsers) AS Users FROM top_user GROUP BY State, District ORDER BY Users DESC LIMIT 10"
#         )
#         df = pd.DataFrame(
#             sqlite_cursor.fetchall(), columns=["State", "District", "RegisteredUsers"]
#         )
#         st.write(df)
#         st.title("Top 10 Registered-users based on States and District")
#         st.bar_chart
# 
# 
# sqlite_cursor = sqlite_conn.cursor()
# 
# # execute a SELECT statement
# sqlite_cursor.execute("SELECT * FROM aggTransa")
# 
# # fetch all rows
# rows = sqlite_cursor.fetchall()
# 
# if SELECT == "Home":
#     col1,col2, = st.columns(2)
#     col1.image(Image.open("C:/Users/omkar/Downloads/phonepe photo/phonepe.png"),width = 500)
#     with col1:
#         st.subheader("PhonePe  is an Indian digital payments and financial technology company headquartered in Bengaluru, Karnataka, India. PhonePe was founded in December 2015, by Sameer Nigam, Rahul Chari and Burzin Engineer. The PhonePe app, based on the Unified Payments Interface (UPI), went live in August 2016. It is owned by Flipkart, a subsidiary of Walmart.")
#         st.download_button("DOWNLOAD THE APP NOW", "https://www.phonepe.com/app-download/")
#     with col2:
#         st.video("C:/Users/omkar/Downloads/phonepe photo/upi.mp4")
# 
# 
#     df = pd.DataFrame(rows, columns=['States', 'Transaction_Year', 'Quarters', 'Transaction_Type', 'Transaction_Count','Transaction_Amount'])
#     fig = px.choropleth(df, locations="States", scope="asia", color="States", hover_name="States",
#         title="Live Geo Visualization of India")
#     st.plotly_chart(fig)
# 
# 
# # Run the Streamlit app
# if __name__ == '__main__':
#     main()

!ls

!ngrok authtoken 2RSYaDxS4EWqbhfXoNjf1Q5yIUD_6d7nZvZSWupeccbx47GKM

!ngrok

from pyngrok import ngrok

#!nohub streamlit run app.py
!streamlit run app.py&>/dev/null&

!pgrep streamlit

publ_url =ngrok.connect(8501)

publ_url