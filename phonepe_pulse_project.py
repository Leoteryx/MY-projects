# -*- coding: utf-8 -*-
"""phonepe_pulse_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qk7BhCA39MD0QDt-dH7k0Ssds3Y8uqKP
"""

!pip install GitPython

import csv
import subprocess
import pandas as pd
import requests
import git
import pandas as pd

import os
import json
import pandas as pd

# Clone the GitHub repository
repo_url = "https://github.com/phonepe/pulse.git"
clone_dir = "pulse"

os.system(f"git clone {repo_url} {clone_dir}")

root_dir = os.path.join(clone_dir, "data", "aggregated", "transaction", "country", "india", "state")

data_list = []

for state_directory in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_directory)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for transaction_data in data['data']['transactionData']:
                                trans_data = {
                                    'States': state_directory,
                                    'Transaction_Year': year_dir,
                                    'Transaction_Type': transaction_data['name'],
                                    'Transaction_Count': transaction_data['paymentInstruments'][0]['count'],
                                    'Transaction_Amount': transaction_data['paymentInstruments'][0]['amount']
                                }
                                data_list.append(trans_data)

# Convert list of dictionaries to a DataFrame
data1 = pd.DataFrame(data_list)
data1.head()

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/aggregated/user/country/india/state'
data2_list = []

for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):
        for json_file in os.listdir(state_path):
            if json_file.endswith('.json'):
                with open(os.path.join(state_path, json_file), 'r') as f:
                    json_data = json.load(f)
                    if isinstance(json_data, list):
                        data2_list.extend(json_data)
                    else:
                        data2_list.append(json_data)
        if data2_list:
            data2 = pd.json_normalize(data2_list)
            data2['subfolder'] = state_dir
            data2['subsubfolder'] = 'state'
        else:
            data2 = pd.DataFrame()
data2.head()

data2 = pd.DataFrame(data_list)

data2

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list = []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for hoverDataList in data['data']['hoverDataList']:
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': hoverDataList['name'],
                                    'Transaction_Type': hoverDataList['metric'][0]['type'],
                                    'Transaction_Count': hoverDataList['metric'][0]['amount']
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data3 = pd.DataFrame(data_list)

data3

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/map/user/hover/country/india/state'

data_list = []

# Loop over all the state folders
for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for district, values in data['data']['hoverData'].items():
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarter': int(json_file.split('.')[0]),
                                    'District': district,
                                    'RegisteredUsers': values['registeredUsers'],
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data4 = pd.DataFrame(data_list)

data4

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

data_list = []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for districts in data['data']['districts']:
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': districts['entityName'],
                                    'Transaction_Type': districts['metric']['type'],
                                    'Transaction_Count': districts['metric']['count'],
                                    'Transaction_Amount': districts['metric']['amount']
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data5 = pd.DataFrame(data_list)

data5

#import plotly.express as px

## Read the geojson file for India
#with open('india_states.geojson', 'r') as f:
#    geojson = f.read()

## Create a choropleth map
#fig = px.choropleth(
#    data_frame=data5,
#    geojson=geojson,
#    locations='States',
#    featureidkey='properties.NAME_1',
#    color='Transaction_Count',
#    hover_name='States',
#    title='Transaction Counts by State in India',
#    labels={'Transaction_Count': 'Transaction Count'}
#)

## Customize the map layout
#fig.update_geos(fitbounds='locations', visible=False)

## Show the map
#fig.show()

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/top/user/country/india/state'

# Initialize empty list to hold dictionaries of data for each JSON file
data_list = []

# Loop over all the state folders
for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for district in data['data']['districts']:
                                row_dict = {
                                    'State': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': district['name'] if 'name' in district else district['pincode'],
                                    'RegisteredUsers': district['registeredUsers'],
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data6 = pd.DataFrame(data_list)
data6

# Drop any duplicates
d1 = data1.drop_duplicates()
#d2 = df2.drop_duplicates()
d3 = data3.drop_duplicates()
d4 = data4.drop_duplicates()
d5 = data5.drop_duplicates()
d6 = data6.drop_duplicates()

#checking Null values
null_counts = d1.isnull().sum()
print(null_counts)

#null_counts = d2.isnull().sum()
#print(null_counts)

null_counts = d3.isnull().sum()
print(null_counts)

null_counts = d4.isnull().sum()
print(null_counts)

null_counts = d5.isnull().sum()
print(null_counts)

null_counts = d6.isnull().sum()
print(null_counts)

#converting all dataframes in to csv
d1.to_csv('map_tran.csv', index=False)
#df2.to_csv('agg_user.csv', index=False)
d3.to_csv('agg_trans.csv', index=False)
d4.to_csv('map_user.csv', index=False)
d5.to_csv('top_tran.csv', index=False)
d6.to_csv('top_user.csv', index=False)

Agg_trans = pd.read_csv(r'/content/agg_trans.csv')
Agg_trans = pd.read_csv(r'/content/map_user.csv')
Agg_trans = pd.read_csv(r'/content/top_tran.csv')
Agg_trans = pd.read_csv(r'/content/top_user.csv')
Agg_trans = pd.read_csv(r'/content/map_tran.csv')
#Agg_trans = pd.read_csv(r'/content/agg_user.csv')

!pip install mysql-connector-python
!pip install streamlit plotly mysql-connector-python
!pip install streamlit
!pip install streamlit_option_menu

import mysql.connector
import pandas as pd
#import psycopg2
import streamlit as st
import PIL
from PIL import Image
from streamlit_option_menu import option_menu
import plotly.express as px
import pandas as pd

import requests

import mysql.connector

import sqlite3

import sqlite3
import pandas as pd
sqlite_conn = sqlite3.connect('phonepedata.db')
sqlite_cursor = sqlite_conn.cursor()

# Create the playlist table in SQLite
sqlite_cursor.execute('''
    CREATE TABLE IF NOT EXISTS Agg_trans (
        States VARCHAR(255),
        Transaction_Year DATETIME,
        Quarters INTEGER,
        District VARCHAR(255),
        Transaction_Type VARCHAR(255),
        Transaction_Count INTEGER
    )
''')
sqlite_cursor.execute('''
   CREATE TABLE IF NOT EXISTS map_user (
        States VARCHAR(255),
        Quarters INTEGER,
        Transaction_Year DATETIME,
        District VARCHAR(255),
        RegisteredUsers INTEGER
    )
''')
sqlite_cursor.execute('''
    CREATE TABLE IF NOT EXISTS map_tran(
        States VARCHAR(255),
        Transaction_Year DATETIME,
        Quarters INTEGER,
        District VARCHAR(255),
        Transaction_Type VARCHAR(255),
        Transaction_Count INTEGER
    )
''')

sqlite_cursor.execute('''
    CREATE TABLE IF NOT EXISTS top_tran (
        Transaction_Year DATETIME,
        Quarter INTEGER,
        District VARCHAR(255),
        Transaction_Type VARCHAR(255),
        Transaction_Count INTEGER,
        Transaction_Amount INTEGER
    )
 ''')

sqlite_cursor.execute('''
    CREATE TABLE IF NOT EXISTS top_user (
        States VARCHAR(255),
        Transaction_Year DATETIME,
        Quarter INTEGER,
        District VARCHAR(255),
        RegisteredUsers INTEGER
    )
''')

# Commit changes and close connections
sqlite_conn.commit()
sqlite_conn.close()

import sqlite3
import pandas as pd

sqlite_conn = sqlite3.connect('phonepedata.db')

Agg_trans.to_sql('Agg_trans', sqlite_conn, if_exists='append', index=False)
#map_user.to_sql('map_user', sqlite_conn, if_exists='append', index=False)
#map_tran.to_sql('map_tran', sqlite_conn, if_exists='append', index=False)
#top_tran.to_sql('top_tran', sqlite_conn, if_exists='append', index=False)
#Agg_trans.to_sql('top_user', sqlite_conn, if_exists='append', index=False)

sqlite_conn.commit()
sqlite_conn.close()

import sqlite3

# Connect to the SQLite database
sqlite_conn = sqlite3.connect('phonepedata.db')
sqlite_cursor = sqlite_conn.cursor()

# Execute a SELECT query to retrieve all data from the Agg_trans table
sqlite_cursor.execute('SELECT * FROM Agg_trans')
sqlite_cursor.execute('SELECT * FROM map_user')
sqlite_cursor.execute('SELECT * FROM map_tran')
sqlite_cursor.execute('SELECT * FROM top_tran')
sqlite_cursor.execute('SELECT * FROM top_user')

# Fetch all the rows and print the data
all_rows = sqlite_cursor.fetchall()
for row in all_rows:
    print(row)

# Close the connection
sqlite_conn.close()

!pip install streamlit
!pip install db-sqlite3
!pip install pyngrok --upgrade

import streamlit as st
import pandas as pd
import plotly.express as px
from PIL import Image

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import plotly.express as px
# from PIL import Image
# import sqlite3
# import io
# from google.colab import files
# import matplotlib.pyplot as plt
# 
# sqlite_conn = sqlite3.connect('phonepedata.db')
# sqlite_cursor = sqlite_conn.cursor()
# 
# # Function to plot the data on the India map
# def plot_geo_map():
#     data_path = "/content/agg_trans.csv"
#     Agg_trans = pd.read_csv(data_path)
# 
#     indian_states_path = "/content/drive/MyDrive/Longitude_Latitude_State_Table.csv"
#     Indian_States = pd.read_csv(indian_states_path)
#     Indian_States.rename(columns={"code": "States"}, inplace=True)
#     if "States" in Agg_trans.columns and "States" in Indian_States.columns:
#         # Merge Agg_trans with Indian_States based on the "States" column
#         merged_data = pd.merge(Agg_trans, Indian_States, on="States")
# 
# 
#     fig = px.choropleth(
#         merged_data,
#         geojson="https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson",
#         featureidkey='properties.ST_NM',
#         locations='States',
#         color='Transaction_Count',  # Replace with the column containing the data you want to plot
#         hover_name='States',  # Update hover_name to match the column name in the DataFrame
#         hover_data=['Transaction_Count'],  # Add additional columns for more information on hover
#         scope="asia"
#     )
# 
#     fig.update_geos(fitbounds="locations", visible=False)
#     fig.update_layout(
#         title_text="Geo India Map",
#         title_x=0.5,
#         margin={"r": 0, "t": 40, "l": 0, "b": 0}
#     )
# 
#     return fig
# 
# def main():
#     SELECT = st.sidebar.selectbox(
#         "Select an option",
#         ["About", "Home", "Basic insights", "Contact"],
#         index=2,
#         format_func=lambda x: x.upper()
#     )
# 
#     if SELECT == "Basic insights":
#         st.title("BASIC INSIGHTS")
#         st.write("----")
#         st.subheader("Let's know some basic insights about the data")
#         options = [
#             "-- Select --",
#             "Top 10 states based on year and amount of transaction",
#             "List 10 states based on type and amount of transaction",
#             "Top 5 Transaction_Type based on Transaction_Amount",
#             "Top 10 Registered-users based on States and District"
#         ]
#         select = st.selectbox("Select an option", options)
# 
#         if select == "Top 10 states based on year and amount of transaction":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT States, Transaction_Year, SUM(Transaction_Amount) AS Total_Transaction_Amount FROM Agg_trans GROUP BY States, Transaction_Year ORDER BY Total_Transaction_Amount DESC LIMIT 10"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["States", "Transaction_Year", "Total_Transaction_Amount"]
#             )
#             st.table(df)
#             st.title("Top 10 states and amount of transaction")
#             st.bar_chart(data=df, x="Total_Transaction_Amount", y="States")
# 
#         elif select == "List 10 states based on type and amount of transaction":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT States, SUM(Transaction_Count) AS Total_Transaction_Count FROM Agg_trans GROUP BY States ORDER BY Total_Transaction_Count ASC LIMIT 10"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["States", "Total_Transaction_Count"]
#             )
#             st.table(df)
#             st.title("List 10 states based on type and amount of transaction")
#             st.bar_chart(data=df, x="Total_Transaction_Count", y="States")
# 
#         elif select == "Top 5 Transaction_Type based on Transaction_Amount":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT Transaction_Type, SUM(Transaction_Amount) AS Total_Transaction_Amount FROM Agg_trans GROUP BY Transaction_Type ORDER BY Total_Transaction_Amount DESC LIMIT 5"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["Transaction_Type", "Total_Transaction_Amount"]
#             )
#             st.table(df)
#             st.title("Top 5 Transaction_Type based on Transaction_Amount")
#             st.bar_chart(data=df, x="Transaction_Type", y="Total_Transaction_Amount")
# 
#         elif select == "Top 10 Registered-users based on States and District":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT States, District, SUM(RegisteredUsers) AS Total_Registered_Users FROM Agg_trans GROUP BY States, District ORDER BY Total_Registered_Users DESC LIMIT 10"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["States", "District", "Total_Registered_Users"]
#             )
#             st.table(df)
#             st.title("Top 10 Registered-users based on States and District")
#             st.bar_chart(data=df, x="Total_Registered_Users", y="States")
# 
#     elif SELECT == "Home":
#         st.title("HOME")
#         st.plotly_chart(plot_geo_map())
# 
# 
#         # fetch all rows
#         rows = sqlite_cursor.fetchall()
# 
#         image_path = "/content/drive/MyDrive/392480-phone-pe.jpeg"
#         image = Image.open(image_path)
#         st.image(image, use_column_width=True)
# 
#         st.subheader("PhonePe is an Indian digital payments and financial technology company headquartered in Bengaluru, Karnataka, India. PhonePe was founded in December 2015, by Sameer Nigam, Rahul Chari and Burzin Engineer. The PhonePe app, based on the Unified Payments Interface (UPI), went live in August 2016. It is owned by Flipkart, a subsidiary of Walmart.")
#         st.download_button("DOWNLOAD THE APP NOW", "https://www.phonepe.com/app-download/")
# 
#         st.video("https://youtu.be/WUkw3LVjhQk")  #https://youtu.be/WUkw3LVjhQk
# 
# 
#     elif SELECT == "About":
#         st.title("ABOUT")
#         st.video("https://youtu.be/WUkw3LVjhQk")
# 
#         image_path = "/content/drive/MyDrive/392480-phone-pe.jpeg"
#         image = Image.open(image_path)
#         st.image(image, use_column_width=True)
# 
#         st.write("---")
#         st.subheader("The Indian digital payments story has truly captured the world's imagination. From the largest towns to the remotest villages, there is a payments revolution being driven by the penetration of mobile phones, mobile internet and states-of-the-art payments infrastructure built as Public Goods championed by the central bank and the government. Founded in December 2015, PhonePe has been a strong beneficiary of the API-driven digitization of payments in India. When we started, we were constantly looking for granular and definitive data sources on digital payments in India. PhonePe Pulse is our way of giving back to the digital payments ecosystem.")
#         st.write("---")
#         st.title("THE BEAT OF PHONEPE")
#         st.write("---")
#         st.subheader("PhonePe became a leading digital payments company")
#         st.image(image, width=400)
# 
#         with open("/content/drive/MyDrive/annualreport.pdf", "rb") as f:
#             data = f.read()
#         st.download_button("DOWNLOAD REPORT", data, file_name="annualreport.pdf")
# 
# 
#     elif SELECT == "Contact":
#         name = "surya teja"
#         mail = (f'{"Mail :"}  {"12344@gmail.com"}')
#         description = "An Aspiring DATA-SCIENTIST..!"
#         social_media = {
#             "GITHUB": "https://github.com/iooo",
#             "LINKEDIN": "https://www.linkedin.com/in/surya-1234/"}
# 
#         col1, col2 = st.columns(2)
# 
#         with col1:
#             st.title('Phonepe Pulse data visualisation')
#             st.write("The goal of this project is to extract data from the Phonepe pulse Github repository, transform and clean the data, insert it into a MySQL database, and create a live geo visualization dashboard using Streamlit and Plotly in Python. The dashboard will display the data in an interactive and visually appealing manner, with at")
#             st.write("---")
#             st.subheader(mail)
#         st.write("#")
#         cols = st.columns(len(social_media))
#         for index, (platform, link) in enumerate(social_media.items()):
#             cols[index].write(f"[{platform}]({link})")
# 
# # Run the Streamlit app
# if __name__ == '__main__':
#     st.title("PhonePe Dashboard")
#     st.sidebar.title("Navigation")
#     main()

from google.colab import drive
drive.mount('/content/drive')

!ls

!ngrok authtoken 2RSYaDxS4EWqbhfXoNjf1Q5yIUD_6d7nZvZSWupeccbx47GKM

!ngrok

from pyngrok import ngrok

#!nohub streamlit run app.py
!streamlit run app.py&>/dev/null&

!pgrep streamlit

publ_url =ngrok.connect(8501)

publ_url
