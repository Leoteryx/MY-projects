# -*- coding: utf-8 -*-
"""phonepe_pulse_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qk7BhCA39MD0QDt-dH7k0Ssds3Y8uqKP
"""

!pip install GitPython

import csv
import subprocess
import pandas as pd
import requests
import git
import pandas as pd

import os
import json
import pandas as pd

# Clone the GitHub repository
repo_url = "https://github.com/phonepe/pulse.git"
clone_dir = "pulse"

os.system(f"git clone {repo_url} {clone_dir}")

root_dir = os.path.join(clone_dir, "data", "aggregated", "transaction", "country", "india", "state")

data_list = []

for state_directory in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_directory)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for transaction_data in data['data']['transactionData']:
                                trans_data = {
                                    'States': state_directory,
                                    'Transaction_Year': year_dir,
                                    'Transaction_Type': transaction_data['name'],
                                    'Transaction_Count': transaction_data['paymentInstruments'][0]['count'],
                                    'Transaction_Amount': transaction_data['paymentInstruments'][0]['amount']
                                }
                                data_list.append(trans_data)

# Convert list of dictionaries to a DataFrame
data1 = pd.DataFrame(data_list)
data1.head()

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/aggregated/user/country/india/state'
data2_list = []

for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):
        for json_file in os.listdir(state_path):
            if json_file.endswith('.json'):
                with open(os.path.join(state_path, json_file), 'r') as f:
                    json_data = json.load(f)
                    if isinstance(json_data, list):
                        data2_list.extend(json_data)
                    else:
                        data2_list.append(json_data)
        if data2_list:
            data2 = pd.json_normalize(data2_list)
            data2['subfolder'] = state_dir
            data2['subsubfolder'] = 'state'
        else:
            data2 = pd.DataFrame()
data2.head()

data2 = pd.DataFrame(data_list)

data2

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list = []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for hoverDataList in data['data']['hoverDataList']:
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': hoverDataList['name'],
                                    'Transaction_Type': hoverDataList['metric'][0]['type'],
                                    'Transaction_Count': hoverDataList['metric'][0]['amount']
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data3 = pd.DataFrame(data_list)

data3

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/map/user/hover/country/india/state'

data_list = []

# Loop over all the state folders
for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for district, values in data['data']['hoverData'].items():
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarter': int(json_file.split('.')[0]),
                                    'District': district,
                                    'RegisteredUsers': values['registeredUsers'],
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data4 = pd.DataFrame(data_list)

data4

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

data_list = []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for districts in data['data']['districts']:
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': districts['entityName'],
                                    'Transaction_Type': districts['metric']['type'],
                                    'Transaction_Count': districts['metric']['count'],
                                    'Transaction_Amount': districts['metric']['amount']
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data5 = pd.DataFrame(data_list)

data5

#import plotly.express as px

## Read the geojson file for India
#with open('india_states.geojson', 'r') as f:
#    geojson = f.read()

## Create a choropleth map
#fig = px.choropleth(
#    data_frame=data5,
#    geojson=geojson,
#    locations='States',
#    featureidkey='properties.NAME_1',
#    color='Transaction_Count',
#    hover_name='States',
#    title='Transaction Counts by State in India',
#    labels={'Transaction_Count': 'Transaction Count'}
#)

## Customize the map layout
#fig.update_geos(fitbounds='locations', visible=False)

## Show the map
#fig.show()

import os
import json
import pandas as pd

root_dir = '/content/pulse/data/top/user/country/india/state'

# Initialize empty list to hold dictionaries of data for each JSON file
data_list = []

# Loop over all the state folders
for state_dir in os.listdir(root_dir):
    state_path = os.path.join(root_dir, state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for district in data['data']['districts']:
                                row_dict = {
                                    'State': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'District': district['name'] if 'name' in district else district['pincode'],
                                    'RegisteredUsers': district['registeredUsers'],
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
data6 = pd.DataFrame(data_list)
data6

# Drop any duplicates
d1 = data1.drop_duplicates()
#d2 = df2.drop_duplicates()
d3 = data3.drop_duplicates()
d4 = data4.drop_duplicates()
d5 = data5.drop_duplicates()
d6 = data6.drop_duplicates()

#checking Null values
null_counts = d1.isnull().sum()
print(null_counts)

#null_counts = d2.isnull().sum()
#print(null_counts)

null_counts = d3.isnull().sum()
print(null_counts)

null_counts = d4.isnull().sum()
print(null_counts)

null_counts = d5.isnull().sum()
print(null_counts)

null_counts = d6.isnull().sum()
print(null_counts)

#converting all dataframes in to csv
d1.to_csv('agg_trans.csv', index=False)
#df2.to_csv('agg_user.csv', index=False)
d3.to_csv('map_tran.csv', index=False)
d4.to_csv('map_user.csv', index=False)
d5.to_csv('top_tran.csv', index=False)
d6.to_csv('top_user.csv', index=False)

Agg_trans = pd.read_csv(r'/content/agg_trans.csv')
map_tran = pd.read_csv(r'/content/map_tran.csv')
map_user = pd.read_csv(r'/content/map_user.csv')
top_tran = pd.read_csv(r'/content/top_tran.csv')
top_user = pd.read_csv(r'/content/top_user.csv')
#Agg_trans = pd.read_csv(r'/content/agg_user.csv')

!pip install mysql-connector-python
!pip install streamlit plotly mysql-connector-python
!pip install streamlit
!pip install streamlit_option_menu

import mysql.connector
import pandas as pd
#import psycopg2
import streamlit as st
import PIL
from PIL import Image
from streamlit_option_menu import option_menu
import plotly.express as px
import pandas as pd

import requests

import mysql.connector

import sqlite3

#sqlite_conn = sqlite3.connect('phonepe.db')
#sqlite_cursor = sqlite_conn.cursor()

import sqlite3
import pandas as pd
conn = sqlite3.connect('example.db')

# Create the playlist table in SQLite
sqlite_cursor.execute('''
    CREATE TABLE IF NOT EXISTS Agg_trans (
        States VARCHAR(255),
        Transaction_Year DATETIME,
        Transaction_Type VARCHAR(255),
        Transaction_Count INTEGER,
        Transaction_Amount INTEGER
    )
''')

sqlite_cursor.execute('''
   CREATE TABLE IF NOT EXISTS map_tran (
        States VARCHAR(255),
        Transaction_Year DATETIME,
        Transaction_Type VARCHAR(255),
        Transaction_Count INTEGER,
        Transaction_Amount INTEGER
    )
''')
sqlite_cursor.execute('''
    CREATE TABLE IF NOT EXISTS map_user(
        States VARCHAR(255),
        Transaction_Year DATETIME,
        Quarters INTEGER,
        District VARCHAR(255),
        Transaction_Type VARCHAR(255),
        Transaction_Count INTEGER
    )
''')

sqlite_cursor.execute('''
    CREATE TABLE IF NOT EXISTS top_tran (
        States VARCHAR(255),
        Transaction_Year DATETIME,
        Quarter INTEGER,
        District VARCHAR(255),
        RegisteredUsers INTEGER
    )
''')
# Commit changes and close connections
#sqlite_conn.commit()
#sqlite_conn.close()

import sqlite3

# Connect to the SQLite database
sqlite_conn = sqlite3.connect('example.db')
sqlite_cursor = sqlite_conn.cursor()

# Sample data for Agg_trans table
agg_trans_data = [
    ('Andhra Pradesh', '2021-01-01', 'UPI', 23320, 210855020),
    ('Andhra Pradesh', '2021-01-01', 'Wallet', 38138, 6466355),
    ('Andhra Pradesh', '2021-01-01', 'Cards', 4293, 34528813),
    ('Andhra Pradesh', '2021-01-01', 'Bank Account', 4411, 33470393),
    # More rows of data...
]

# Insert data into Agg_trans table
sqlite_cursor.executemany("INSERT INTO Agg_trans VALUES (?, ?, ?, ?, ?)", agg_trans_data)
sqlite_conn.commit()

# Sample data for map_tran table
map_tran_data = [
    ('Andhra Pradesh', '2021-01-01', 'UPI', 23320, 210855020),
    ('Andhra Pradesh', '2021-01-01', 'Wallet', 38138, 6466355),
    ('Andhra Pradesh', '2021-01-01', 'Cards', 4293, 34528813),
    ('Andhra Pradesh', '2021-01-01', 'Bank Account', 4411, 33470393),
    # More rows of data...
]

# Insert data into map_tran table
sqlite_cursor.executemany("INSERT INTO map_tran VALUES (?, ?, ?, ?, ?)", map_tran_data)
sqlite_conn.commit()

# Sample data for map_user table
map_user_data = [
    ('Andhra Pradesh', '2021-01-01', 1, 'Anantapur', 'UPI', 2414),
    ('Andhra Pradesh', '2021-01-01', 1, 'Anantapur', 'Wallet', 4181),
    ('Andhra Pradesh', '2021-01-01', 1, 'Anantapur', 'Cards', 386),
    ('Andhra Pradesh', '2021-01-01', 1, 'Anantapur', 'Bank Account', 431),
    # More rows of data...
]

# Insert data into map_user table
sqlite_cursor.executemany("INSERT INTO map_user VALUES (?, ?, ?, ?, ?, ?)", map_user_data)
sqlite_conn.commit()

# Sample data for top_tran table
top_tran_data = [
    ('Andhra Pradesh', '2021-01-01', 1, 'Anantapur', 17470),
    ('Andhra Pradesh', '2021-01-01', 1, 'Chittoor', 19133),
    ('Andhra Pradesh', '2021-01-01', 1, 'East Godavari', 33291),
    ('Andhra Pradesh', '2021-01-01', 1, 'Guntur', 26582),
    # More rows of data...
]

# Insert data into top_tran table
sqlite_cursor.executemany("INSERT INTO top_tran VALUES (?, ?, ?, ?, ?)", top_tran_data)
sqlite_conn.commit()

# Print Agg_trans table
sqlite_cursor.execute("SELECT * FROM Agg_trans")
agg_trans_rows = sqlite_cursor.fetchall()
print("Agg_trans table:")
for row in agg_trans_rows:
    print(row)

# Print map_tran table
sqlite_cursor.execute("SELECT * FROM map_tran")
map_tran_rows = sqlite_cursor.fetchall()
print("map_tran table:")
for row in map_tran_rows:
    print(row)

# Print map_user table
sqlite_cursor.execute("SELECT * FROM map_user")
map_user_rows = sqlite_cursor.fetchall()
print("map_user table:")
for row in map_user_rows:
    print(row)

# Print top_tran table
sqlite_cursor.execute("SELECT * FROM top_tran")
top_tran_rows = sqlite_cursor.fetchall()
print("top_tran table:")
for row in top_tran_rows:
    print(row)

# Close the database connection
#sqlite_conn.close()

#sqlite_cursor = conn.cursor()
# Define table names
#table1_name = 'table1'
#table2_name = 'table2'
#table3_name = 'table3'
#table4_name = 'table4'

# Store data in SQLite tables
#data1.to_sql(table1_name, conn, if_exists='replace', index=False)
#data2.to_sql(table2_name, conn, if_exists='replace', index=False)
#data3.to_sql(table3_name, conn, if_exists='replace', index=False)
#data4.to_sql(table4_name, conn, if_exists='replace', index=False)

#create_table_query1 = '''
#CREATE TABLE IF NOT EXISTS aggTransa (
#    id INTEGER PRIMARY KEY,
#    transaction_date DATETIME,
#    Transaction_Amount INTEGER,
#    description TEXT
#)
#'''

#create_table_query2 = '''
#CREATE TABLE IF NOT EXISTS top_tran (
#    States VARCHAR(255),
#    Transaction_Year INTEGER,
#    Transaction_Count REAL
#)
#'''

# Execute the CREATE TABLE statements
#sqlite_cursor.execute(create_table_query1)
#sqlite_cursor.execute(create_table_query2)

#conn.commit()
#conn.close()

# fetch all rows
rows = sqlite_cursor.fetchall()

# print the rows
for row in rows:
  print(row)

!pip install streamlit
!pip install db-sqlite3
!pip install pyngrok --upgrade

import streamlit as st
import pandas as pd
import plotly.express as px
from PIL import Image

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import plotly.express as px
# from PIL import Image
# import sqlite3
# import io
# from google.colab import files
# import matplotlib.pyplot as plt
# 
# sqlite_conn = sqlite3.connect('example.db')
# sqlite_cursor = sqlite_conn.cursor()
# 
# 
# def main():
#     SELECT = st.sidebar.selectbox(
#         "Select an option",
#         ["About", "Home", "Basic insights", "Contact"],
#         index=2,
#         format_func=lambda x: x.upper()
#     )
# 
#     if SELECT == "Basic insights":
#         st.title("BASIC INSIGHTS")
#         st.write("----")
#         st.subheader("Let's know some basic insights about the data")
#         options = [
#             "-- Select --",
#             "Top 10 states based on year and amount of transaction",
#             "List 10 states based on type and amount of transaction",
#             "Top 5 Transaction_Type based on Transaction_Amount",
#             "Top 10 Registered-users based on States and District"
#         ]
#         select = st.selectbox("Select an option", options)
# 
#         if select == "Top 10 states based on year and amount of transaction":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT States, Transaction_Year, SUM(Transaction_Amount) AS Total_Transaction_Amount FROM top_tran GROUP BY States, Transaction_Year ORDER BY Total_Transaction_Amount DESC LIMIT 10"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["States", "Transaction_Year", "Total_Transaction_Amount"]
#             )
#             st.table(df)
#             st.title("Top 10 states and amount of transaction")
#             st.bar_chart(data=df, x="Total_Transaction_Amount", y="States")
# 
#         elif select == "List 10 states based on type and amount of transaction":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT States, SUM(Transaction_Count) AS Total_Transaction_Count FROM map_tran GROUP BY States ORDER BY Total_Transaction_Count ASC LIMIT 10"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["States", "Total_Transaction_Count"]
#             )
#             st.table(df)
#             st.title("List 10 states based on type and amount of transaction")
#             st.bar_chart(data=df, x="Total_Transaction_Count", y="States")
# 
#         elif select == "Top 5 Transaction_Type based on Transaction_Amount":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT Transaction_Type, SUM(Transaction_Amount) AS Total_Transaction_Amount FROM Agg_trans GROUP BY Transaction_Type ORDER BY Total_Transaction_Amount DESC LIMIT 5"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["Transaction_Type", "Total_Transaction_Amount"]
#             )
#             st.table(df)
#             st.title("Top 5 Transaction_Type based on Transaction_Amount")
#             st.bar_chart(data=df, x="Transaction_Type", y="Total_Transaction_Amount")
# 
#         elif select == "Top 10 Registered-users based on States and District":
#             sqlite_cursor.execute(
#                 "SELECT DISTINCT States, District, SUM(RegisteredUsers) AS Total_Registered_Users FROM top_tran GROUP BY States, District ORDER BY Total_Registered_Users DESC LIMIT 10"
#             )
#             df = pd.DataFrame(
#                 sqlite_cursor.fetchall(),
#                 columns=["States", "District", "Total_Registered_Users"]
#             )
#             st.table(df)
#             st.title("Top 10 Registered-users based on States and District")
#             st.bar_chart(data=df, x="Total_Registered_Users", y="States")
# 
# 
#     elif SELECT == "Home":
#         st.title("HOME")
# 
#         image_path = "/content/drive/MyDrive/392480-phone-pe.jpeg"
#         image = Image.open(image_path)
#         st.image(image, use_column_width=True)
# 
#         st.subheader("PhonePe is an Indian digital payments and financial technology company headquartered in Bengaluru, Karnataka, India. PhonePe was founded in December 2015, by Sameer Nigam, Rahul Chari and Burzin Engineer. The PhonePe app, based on the Unified Payments Interface (UPI), went live in August 2016. It is owned by Flipkart, a subsidiary of Walmart.")
#         st.download_button("DOWNLOAD THE APP NOW", "https://www.phonepe.com/app-download/")
# 
#         st.video("https://youtu.be/WUkw3LVjhQk")  #https://youtu.be/WUkw3LVjhQk
# 
#         # Your code for other content in the home section
# 
#         df = pd.DataFrame(columns=['States', 'Transaction_Year', 'Quarters', 'Transaction_Type', 'Transaction_Count', 'Transaction_Amount'])
#         fig = px.choropleth(df, locations="States", scope="asia", color="States", hover_name="States", title="Live Geo Visualization of India")
#         st.plotly_chart(fig)
# 
#     elif SELECT == "About":
#         st.title("ABOUT")
#         st.video("https://youtu.be/WUkw3LVjhQk")
# 
#         image_path = "/content/drive/MyDrive/392480-phone-pe.jpeg"
#         image = Image.open(image_path)
#         st.image(image, use_column_width=True)
# 
#         st.write("---")
#         st.subheader("The Indian digital payments story has truly captured the world's imagination. From the largest towns to the remotest villages, there is a payments revolution being driven by the penetration of mobile phones, mobile internet and states-of-the-art payments infrastructure built as Public Goods championed by the central bank and the government. Founded in December 2015, PhonePe has been a strong beneficiary of the API-driven digitization of payments in India. When we started, we were constantly looking for granular and definitive data sources on digital payments in India. PhonePe Pulse is our way of giving back to the digital payments ecosystem.")
#         st.write("---")
#         st.title("THE BEAT OF PHONEPE")
#         st.write("---")
#         st.subheader("PhonePe became a leading digital payments company")
#         st.image(image, width=400)
# 
#         with open("/content/annual report.pdf", "rb") as f:
#             data = f.read()
#         st.download_button("DOWNLOAD REPORT", data, file_name="annual report.pdf")
# 
#         st.image(Image.open("/content/report.jpeg"), width=800)
# 
#     elif SELECT == "Contact":
#         name = "surya teja"
#         mail = (f'{"Mail :"}  {"12344@gmail.com"}')
#         description = "An Aspiring DATA-SCIENTIST..!"
#         social_media = {
#             "GITHUB": "https://github.com/iooo",
#             "LINKEDIN": "https://www.linkedin.com/in/surya-1234/"}
# 
#         col1, col2 = st.columns(2)
# 
#         with col1:
#             st.title('Phonepe Pulse data visualisation')
#             st.write("The goal of this project is to extract data from the Phonepe pulse Github repository, transform and clean the data, insert it into a MySQL database, and create a live geo visualization dashboard using Streamlit and Plotly in Python. The dashboard will display the data in an interactive and visually appealing manner, with at")
#             st.write("---")
#             st.subheader(mail)
#         st.write("#")
#         cols = st.columns(len(social_media))
#         for index, (platform, link) in enumerate(social_media.items()):
#             cols[index].write(f"[{platform}]({link})")
# 
# # Run the Streamlit app
# if __name__ == '__main__':
#     st.title("PhonePe Dashboard")
#     st.sidebar.title("Navigation")
#     main()

from google.colab import drive
drive.mount('/content/drive')

!ls

!ngrok authtoken 2RSYaDxS4EWqbhfXoNjf1Q5yIUD_6d7nZvZSWupeccbx47GKM

!ngrok

from pyngrok import ngrok

#!nohub streamlit run app.py
!streamlit run app.py&>/dev/null&

!pgrep streamlit

publ_url =ngrok.connect(8501)

publ_url
